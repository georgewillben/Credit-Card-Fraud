{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I take a look at the predictive capability of the features. I would normally generate new features here, but I found little to no relationships between the variables and the use of domain knowledge is limited due to the anonymous nature of the data set. Also I could tell during the exploratory data analysis stage, that the data would not benefit from log or absolute value transformations. I will use tools to resample the data as well as deturmine the most useful features. Also I will make sure the features are clear of problems such as multicolinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Road Map\n",
    "\n",
    "1) See Which Features Are Worth Using <br>\n",
    "2) Resample Data <br>\n",
    "3) Deal With Multicolinearity <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "# standard scientific libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "\n",
    "# resampling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "# machine learning metrics\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# machine learning models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# time keeping\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.238954</td>\n",
       "      <td>-1.724499</td>\n",
       "      <td>-2.151484</td>\n",
       "      <td>-2.577803</td>\n",
       "      <td>0.993668</td>\n",
       "      <td>3.565492</td>\n",
       "      <td>-1.785957</td>\n",
       "      <td>0.860122</td>\n",
       "      <td>-1.264003</td>\n",
       "      <td>1.567867</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149574</td>\n",
       "      <td>-0.049333</td>\n",
       "      <td>0.278442</td>\n",
       "      <td>0.684735</td>\n",
       "      <td>-0.219028</td>\n",
       "      <td>-0.159167</td>\n",
       "      <td>0.037920</td>\n",
       "      <td>-0.049932</td>\n",
       "      <td>3.466048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.315062</td>\n",
       "      <td>1.630783</td>\n",
       "      <td>0.597001</td>\n",
       "      <td>-0.038359</td>\n",
       "      <td>-0.404580</td>\n",
       "      <td>-0.965712</td>\n",
       "      <td>0.212249</td>\n",
       "      <td>0.735381</td>\n",
       "      <td>-1.267926</td>\n",
       "      <td>-0.482635</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.238898</td>\n",
       "      <td>-0.946773</td>\n",
       "      <td>0.323904</td>\n",
       "      <td>0.515632</td>\n",
       "      <td>-0.713000</td>\n",
       "      <td>-0.266503</td>\n",
       "      <td>-0.017794</td>\n",
       "      <td>0.051058</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.908801</td>\n",
       "      <td>0.021184</td>\n",
       "      <td>-2.087997</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>1.161468</td>\n",
       "      <td>0.605244</td>\n",
       "      <td>-0.022371</td>\n",
       "      <td>0.180296</td>\n",
       "      <td>0.283819</td>\n",
       "      <td>-0.497766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293609</td>\n",
       "      <td>1.095842</td>\n",
       "      <td>-0.044874</td>\n",
       "      <td>-1.689517</td>\n",
       "      <td>0.106098</td>\n",
       "      <td>0.007758</td>\n",
       "      <td>0.045164</td>\n",
       "      <td>-0.053068</td>\n",
       "      <td>2.705380</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.811257</td>\n",
       "      <td>0.316556</td>\n",
       "      <td>0.316751</td>\n",
       "      <td>3.880231</td>\n",
       "      <td>0.048454</td>\n",
       "      <td>1.020163</td>\n",
       "      <td>-0.734868</td>\n",
       "      <td>0.233651</td>\n",
       "      <td>0.681423</td>\n",
       "      <td>1.146705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138869</td>\n",
       "      <td>0.700422</td>\n",
       "      <td>0.174064</td>\n",
       "      <td>0.702997</td>\n",
       "      <td>-0.212523</td>\n",
       "      <td>-0.010018</td>\n",
       "      <td>-0.017740</td>\n",
       "      <td>-0.038006</td>\n",
       "      <td>2.851284</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.358817</td>\n",
       "      <td>-1.120881</td>\n",
       "      <td>0.550266</td>\n",
       "      <td>-1.547659</td>\n",
       "      <td>-1.194950</td>\n",
       "      <td>0.275448</td>\n",
       "      <td>-1.201843</td>\n",
       "      <td>0.212889</td>\n",
       "      <td>-2.094285</td>\n",
       "      <td>1.492821</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.340972</td>\n",
       "      <td>-0.636442</td>\n",
       "      <td>0.252758</td>\n",
       "      <td>-0.344160</td>\n",
       "      <td>-0.064282</td>\n",
       "      <td>-0.439622</td>\n",
       "      <td>0.062524</td>\n",
       "      <td>0.013095</td>\n",
       "      <td>3.178470</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  2.238954 -1.724499 -2.151484 -2.577803  0.993668  3.565492 -1.785957   \n",
       "1 -1.315062  1.630783  0.597001 -0.038359 -0.404580 -0.965712  0.212249   \n",
       "2  1.908801  0.021184 -2.087997  0.129310  1.161468  0.605244 -0.022371   \n",
       "3  1.811257  0.316556  0.316751  3.880231  0.048454  1.020163 -0.734868   \n",
       "4  1.358817 -1.120881  0.550266 -1.547659 -1.194950  0.275448 -1.201843   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.860122 -1.264003  1.567867  ... -0.149574 -0.049333  0.278442  0.684735   \n",
       "1  0.735381 -1.267926 -0.482635  ... -0.238898 -0.946773  0.323904  0.515632   \n",
       "2  0.180296  0.283819 -0.497766  ...  0.293609  1.095842 -0.044874 -1.689517   \n",
       "3  0.233651  0.681423  1.146705  ...  0.138869  0.700422  0.174064  0.702997   \n",
       "4  0.212889 -2.094285  1.492821  ... -0.340972 -0.636442  0.252758 -0.344160   \n",
       "\n",
       "        V25       V26       V27       V28    Amount  Class  \n",
       "0 -0.219028 -0.159167  0.037920 -0.049932  3.466048      0  \n",
       "1 -0.713000 -0.266503 -0.017794  0.051058  1.945910      0  \n",
       "2  0.106098  0.007758  0.045164 -0.053068  2.705380      0  \n",
       "3 -0.212523 -0.010018 -0.017740 -0.038006  2.851284      0  \n",
       "4 -0.064282 -0.439622  0.062524  0.013095  3.178470      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "# Note: only use training data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Deturmine Which Features are Worth Using"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to find which features are the most useful before resampling to maximise the amount of information saved.  To find the best columns for linear models I will create some \"brute force\" classifiers to see exactly how well each column can perform as a predictor by itself. I will simply choose a threshold for predicting fraud and non-fraud by trying 50 thresholds and then I will see which threshold gives the best f1-score. The f1-score is the harmonic mean of precision and recall. It increases when both are high and dramatically decreases when either are low. To find the best features for tree based algorithms I will create a random forest model and find the feature importances when it is trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Best Columns For Linear Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create brute force classifier\n",
    "class brute_force_classifier():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.thresholds = None\n",
    "        self.best_score = None\n",
    "        self.best_threshold = None\n",
    "        self.direction = None\n",
    "        \n",
    "    # method for returning predictions\n",
    "    # must set best_threshold and direction\n",
    "    # or call fit method before using\n",
    "    def predict(self, X):\n",
    "        \n",
    "        # depending on the direction, classify each point on whether it is greater then\n",
    "        # or less then the best threshold\n",
    "        if self.direction == \"less_then\":\n",
    "            return [1 if point < self.best_threshold else 0 for point in X]\n",
    "        elif self.direction == \"greater_then\": \n",
    "            return [1 if point > self.best_threshold else 0 for point in X]\n",
    "        else:\n",
    "            return \"error\"\n",
    "        \n",
    "        \n",
    "    \n",
    "    # method for finding best threshold\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # create 200 threshold points\n",
    "        thresholds = np.linspace(X.min(), X.max(), 50)\n",
    "        \n",
    "        # record results for each threshold and for each direction\n",
    "        results_greater_then = []\n",
    "        results_less_then = []\n",
    "        \n",
    "        # test thresholds\n",
    "        for threshold in thresholds:\n",
    "            \n",
    "            # set current threshold to best threshold\n",
    "            self.best_threshold = threshold\n",
    "            \n",
    "            # iterate over both directions to test both\n",
    "            for current_direction in [\"less_then\", \"greater_then\"]:\n",
    "                \n",
    "                # set direction\n",
    "                self.direction = current_direction\n",
    "            \n",
    "                # get results for that threshold\n",
    "                predictions = self.predict(X)\n",
    "                \n",
    "                # save f1 score in results\n",
    "                if current_direction == \"less_then\":\n",
    "                    results_less_then.append(f1_score(y, predictions))\n",
    "                else:\n",
    "                    results_greater_then.append(f1_score(y, predictions))\n",
    "            \n",
    "        # zip results and thresholds and then form a list from the zip\n",
    "        results_thresholds = list(zip(thresholds, results_less_then, results_greater_then))\n",
    "        \n",
    "        # sort list in ascending order\n",
    "        # based on the highest f1-score for results from either direction\n",
    "        sorted_results_thresholds = sorted(results_thresholds, reverse=True, key=lambda g: max([g[1], g[2]]))\n",
    "        \n",
    "        # find and set the best threshold. It will be the first item of the first item in the sorted list\n",
    "        self.best_threshold = sorted_results_thresholds[0][0]\n",
    "        \n",
    "        # find and set the best direction for than threshold using an if else statement\n",
    "        if sorted_results_thresholds[0][1] >= sorted_results_thresholds[0][2]:\n",
    "            self.direction = \"less_then\"\n",
    "        \n",
    "        else:\n",
    "            self.direction = \"greater_then\"\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This cell took 10 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column V1 completed\n",
      "Column V2 completed\n",
      "Column V3 completed\n",
      "Column V4 completed\n",
      "Column V5 completed\n",
      "Column V6 completed\n",
      "Column V7 completed\n",
      "Column V8 completed\n",
      "Column V9 completed\n",
      "Column V10 completed\n",
      "Column V11 completed\n",
      "Column V12 completed\n",
      "Column V13 completed\n",
      "Column V14 completed\n",
      "Column V15 completed\n",
      "Column V16 completed\n",
      "Column V17 completed\n",
      "Column V18 completed\n",
      "Column V19 completed\n",
      "Column V20 completed\n",
      "Column V21 completed\n",
      "Column V22 completed\n",
      "Column V23 completed\n",
      "Column V24 completed\n",
      "Column V25 completed\n",
      "Column V26 completed\n",
      "Column V27 completed\n",
      "Column V28 completed\n",
      "Column Amount completed\n",
      "This cell too 10.983333333333333 minutes to run\n"
     ]
    }
   ],
   "source": [
    "# get results from the brute force classifier for each column\n",
    "\n",
    "# start timer\n",
    "start = time.time()\n",
    "\n",
    "# record results in a dictionary\n",
    "results = {}\n",
    "\n",
    "# instantiate classifier\n",
    "clf = brute_force_classifier()\n",
    "\n",
    "# iterate over each column\n",
    "for col in train_resampled.columns:\n",
    "    \n",
    "    if col != \"Class\":\n",
    "    \n",
    "        # get X_train and y_train\n",
    "        X_train = train[col]\n",
    "        y_train = train[\"Class\"]\n",
    "\n",
    "        # fit classifier\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # find and save score of predictions\n",
    "        predictions = clf.predict(X_train)\n",
    "        results[col] = f1_score(y_train, predictions)\n",
    "        print(f\"Column {col} completed\")\n",
    "    \n",
    "# end timer\n",
    "end = time.time()\n",
    "\n",
    "# display computation time\n",
    "expired = round(end - start)/60\n",
    "print(f\"This cell too {expired} minutes to run\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot results\n",
    "results = results.items()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar([x[0] for x in results], [x[1] for x in results])\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"brute force classifier results for each column (f1-score)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems all of the columns are performing well. We can see here that some columns are approaching an 75% f1-score on the training data just by themselves. To note, the columns that can produce a training f1-score of over 40% are:\n",
    "* V9 \n",
    "* V10\n",
    "* V11\n",
    "* V12\n",
    "* V14\n",
    "* V16\n",
    "* V17\n",
    "* V18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Best Columns For Tree Based Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zasz\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9770580296896085\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train a random forest model on the data\n",
    "# and plot feature importances\n",
    "\n",
    "# seperate X and y variables\n",
    "X, y = train.drop(\"Class\", axis=1), train.Class\n",
    "\n",
    "# create model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# train model\n",
    "rf.fit(X, y)\n",
    "\n",
    "# predict and print f1-score\n",
    "print(\"F1 Score:\", f1_score(y, rf.predict(X)))\n",
    "\n",
    "# plot feature importances\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(X.columns, rf.feature_importances_)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the best features for tree based algorithms are:\n",
    "* V11\n",
    "* V12\n",
    "* V14\n",
    "* V16\n",
    "* V18 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if the f1-score of the classifier lowers if we only use these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9728997289972899\n"
     ]
    }
   ],
   "source": [
    "# see if the f1-score of the random forest model\n",
    "# increases if we only use certain features\n",
    "\n",
    "# create a list of features to use\n",
    "feats = [\"V11\", \"V12\", \"V14\", \"V16\", \"V18\"]\n",
    "\n",
    "# seperate X and y variables\n",
    "X, y = train[feats], train.Class\n",
    "\n",
    "# train model\n",
    "rf.fit(X, y)\n",
    "\n",
    "# predict and print f1-score\n",
    "print(\"F1 Score:\", f1_score(y, rf.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score dropped, but only by a fraction of a percent. I think the information saved during the resampling process is worth it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Resample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having unbalanced data is bad for machine learning algorithms. It induces bias because the algorithms are updated for every row they are trained on and the updates for failure will be much more frequent then the updates for success whenever the model predicts a fraud. This ultimately will make the model perform sub-optimaly. Resampling the data will make it balanced. I will be using the \"NearMiss\" algorithm which will remove non-fraud data points until there are equal amounts of fraud and non-fraud transactions in the data. I will be making one set of data for linear models and another for tree based models. The NearMiss algorithm is distance based. It first finds the distance between each point. Then it finds the points that belong to the majority class that are, on average, the farthest distance away from the points in the manority class. It then removes those points from the majority class one-by-one until the two classes have the same amount of points. This means only the members of the majority class in the closest proximity to the minority class will be saved, thus saving the most information. Since NearMiss is a machine learning model and uses distance it is ussually a good idea to scale the data and remove any unneccesary features. Another important thing to note is that resampled data should never be used for testing, only for training. After the data is resampled it will better expose it to testing and finding multicolinearity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3.67806834,  -8.40024875,   5.95937808,  -8.63385091,\n",
       "        -9.74508771,  -8.41679886, -16.5133029 ,  -5.96002263])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale and resample data for linear models & tree based models\n",
    "\n",
    "# create lists of features to use\n",
    "linear_feats = [\"V9\", \"V10\", \"V11\", \"V12\", \"V14\", \"V16\", \"V17\", \"V18\"]\n",
    "tree_feats = feats # see above\n",
    "\n",
    "# seperate X and y for both linear and tree data\n",
    "lin = train[linear_feats]\n",
    "tree = train[tree_feats]\n",
    "y = train[\"Class\"]\n",
    "\n",
    "# instantiate scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# fit the scaler and transform data\n",
    "lin_scaled = sc.fit_transform(lin)\n",
    "tree_scaled = sc.fit_transform(tree)\n",
    "\n",
    "# instantiate NearMiss object\n",
    "nm = NearMiss()\n",
    "\n",
    "# fit the NearMiss object and resample the scaled data\n",
    "lin_resampled_X, lin_resampled_y = nm.fit_resample(lin_scaled, y)\n",
    "tree_resampled_X, tree_resampled_y = nm.fit_resample(tree_scaled, y)\n",
    "\n",
    "# preview\n",
    "lin_resampled_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.906584</td>\n",
       "      <td>-0.023148</td>\n",
       "      <td>-1.422257</td>\n",
       "      <td>0.655860</td>\n",
       "      <td>0.236239</td>\n",
       "      <td>-0.955042</td>\n",
       "      <td>0.437714</td>\n",
       "      <td>-0.327925</td>\n",
       "      <td>0.677833</td>\n",
       "      <td>-1.031722</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116523</td>\n",
       "      <td>-0.250734</td>\n",
       "      <td>-0.087141</td>\n",
       "      <td>-0.369715</td>\n",
       "      <td>0.297917</td>\n",
       "      <td>-0.629323</td>\n",
       "      <td>-0.003706</td>\n",
       "      <td>0.038490</td>\n",
       "      <td>0.994475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.987336</td>\n",
       "      <td>0.803722</td>\n",
       "      <td>-1.726461</td>\n",
       "      <td>2.777141</td>\n",
       "      <td>1.432907</td>\n",
       "      <td>0.027513</td>\n",
       "      <td>0.565542</td>\n",
       "      <td>-0.052569</td>\n",
       "      <td>-1.477013</td>\n",
       "      <td>0.308132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228136</td>\n",
       "      <td>-0.512410</td>\n",
       "      <td>0.021478</td>\n",
       "      <td>-0.082168</td>\n",
       "      <td>0.542450</td>\n",
       "      <td>-0.002035</td>\n",
       "      <td>-0.069247</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>-0.837584</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.926322</td>\n",
       "      <td>0.036424</td>\n",
       "      <td>-1.457341</td>\n",
       "      <td>0.649868</td>\n",
       "      <td>0.291778</td>\n",
       "      <td>-0.996993</td>\n",
       "      <td>0.460670</td>\n",
       "      <td>-0.361564</td>\n",
       "      <td>0.630039</td>\n",
       "      <td>-1.072727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145436</td>\n",
       "      <td>-0.275812</td>\n",
       "      <td>-0.105116</td>\n",
       "      <td>-0.414568</td>\n",
       "      <td>0.379638</td>\n",
       "      <td>-0.629662</td>\n",
       "      <td>0.003912</td>\n",
       "      <td>0.041304</td>\n",
       "      <td>0.943201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.715710</td>\n",
       "      <td>-0.427951</td>\n",
       "      <td>-1.632028</td>\n",
       "      <td>0.779803</td>\n",
       "      <td>0.056732</td>\n",
       "      <td>-0.961689</td>\n",
       "      <td>0.624765</td>\n",
       "      <td>-0.348329</td>\n",
       "      <td>0.778868</td>\n",
       "      <td>-1.130716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012528</td>\n",
       "      <td>-0.570361</td>\n",
       "      <td>-0.379710</td>\n",
       "      <td>-0.452673</td>\n",
       "      <td>0.150096</td>\n",
       "      <td>-0.667958</td>\n",
       "      <td>-0.119314</td>\n",
       "      <td>0.146349</td>\n",
       "      <td>1.459682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.998509</td>\n",
       "      <td>0.003701</td>\n",
       "      <td>-1.291620</td>\n",
       "      <td>0.247384</td>\n",
       "      <td>0.359023</td>\n",
       "      <td>-0.525482</td>\n",
       "      <td>0.181924</td>\n",
       "      <td>-0.217894</td>\n",
       "      <td>0.778759</td>\n",
       "      <td>-0.892710</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326531</td>\n",
       "      <td>-0.704315</td>\n",
       "      <td>0.193914</td>\n",
       "      <td>0.624652</td>\n",
       "      <td>0.028670</td>\n",
       "      <td>-0.240005</td>\n",
       "      <td>-0.037145</td>\n",
       "      <td>-0.010047</td>\n",
       "      <td>0.606205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  0.906584 -0.023148 -1.422257  0.655860  0.236239 -0.955042  0.437714   \n",
       "1  0.987336  0.803722 -1.726461  2.777141  1.432907  0.027513  0.565542   \n",
       "2  0.926322  0.036424 -1.457341  0.649868  0.291778 -0.996993  0.460670   \n",
       "3  0.715710 -0.427951 -1.632028  0.779803  0.056732 -0.961689  0.624765   \n",
       "4  0.998509  0.003701 -1.291620  0.247384  0.359023 -0.525482  0.181924   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0 -0.327925  0.677833 -1.031722  ... -0.116523 -0.250734 -0.087141 -0.369715   \n",
       "1 -0.052569 -1.477013  0.308132  ... -0.228136 -0.512410  0.021478 -0.082168   \n",
       "2 -0.361564  0.630039 -1.072727  ... -0.145436 -0.275812 -0.105116 -0.414568   \n",
       "3 -0.348329  0.778868 -1.130716  ...  0.012528 -0.570361 -0.379710 -0.452673   \n",
       "4 -0.217894  0.778759 -0.892710  ... -0.326531 -0.704315  0.193914  0.624652   \n",
       "\n",
       "        V25       V26       V27       V28    Amount  Class  \n",
       "0  0.297917 -0.629323 -0.003706  0.038490  0.994475      0  \n",
       "1  0.542450 -0.002035 -0.069247  0.002182 -0.837584      0  \n",
       "2  0.379638 -0.629662  0.003912  0.041304  0.943201      0  \n",
       "3  0.150096 -0.667958 -0.119314  0.146349  1.459682      0  \n",
       "4  0.028670 -0.240005 -0.037145 -0.010047  0.606205      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# place resampled data back into a dataframe\n",
    "\n",
    "\n",
    "# create function to put arrays back into dataframe format\n",
    "def to_dataframe(X, y, feat_names):\n",
    "    \"\"\"Function takes in two arrays and column names then returns a dataframe\n",
    "    X: a 2D array holding feature data\n",
    "    y: a 1D array holding target data\n",
    "    feat_names: A list of strings holding column names for X\"\"\"\n",
    "    \n",
    "    # create dataframes\n",
    "    X_df = pd.Dataframe(X, columns=feat_names)\n",
    "    y_df = pd.Series(y, name=\"Class\")\n",
    "    \n",
    "    # concat and return\n",
    "    return pd.concat([X_df, y_df], axis=1)\n",
    "\n",
    "# call function\n",
    "lin_df_rs = to_dataframe(lin_resampled_X, lin_resampled_y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
